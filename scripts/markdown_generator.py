#!/usr/bin/env python3
"""
Markdown Generator para Blog Vercel
Convierte el output del AI processor a Markdown para Next.js
"""

import json
import os
from datetime import datetime
from typing import Dict, Any
import re

class MarkdownGenerator:
    def __init__(self):
        self.content_dir = "./content/posts"
        self.public_dir = "./public"
        os.makedirs(self.content_dir, exist_ok=True)
        os.makedirs(self.public_dir, exist_ok=True)
    
    def convert_blog_post_to_markdown(self, blog_post_file: str) -> str:
        """Convierte blog post JSON a Markdown con frontmatter"""
        print(f"ğŸ”„ Converting {blog_post_file} to Markdown...")
        
        # Load blog post data
        with open(blog_post_file, 'r', encoding='utf-8') as f:
            blog_post = json.load(f)
        
        # Extract data
        title = blog_post.get('title', 'Tech Digest')
        date = blog_post.get('date', datetime.now().isoformat())
        excerpt = blog_post.get('excerpt', '')
        content = blog_post.get('content', '')
        trends_analysis = blog_post.get('trends_analysis', {})
        metadata = blog_post.get('metadata', {})
        seo = blog_post.get('seo', {})
        
        # Create frontmatter
        frontmatter = f"""---
title: "{title}"
date: "{date}"
excerpt: "{excerpt}"
author: "NovaSecOps"
tags: {json.dumps(seo.get('keywords', ['tech', 'ai', 'news']))}
categories: {json.dumps(list(metadata.get('categories', {}).keys()))}
total_stories: {metadata.get('total_stories', 0)}
sources: {json.dumps(metadata.get('sources', []))}
slug: "{blog_post.get('slug', 'tech-digest')}"
---

"""
        
        # Process content
        if isinstance(content, dict) and content.get('fallback'):
            # Generate content from available data
            processed_content = self.generate_content_from_metadata(metadata, trends_analysis)
        elif isinstance(content, str):
            processed_content = content
        else:
            processed_content = self.generate_content_from_metadata(metadata, trends_analysis)
        
        # Add trends analysis section
        if trends_analysis and isinstance(trends_analysis, dict) and not trends_analysis.get('fallback'):
            trends_section = self.format_trends_analysis(trends_analysis)
            processed_content += f"\n\n{trends_section}"
        
        # Complete markdown
        markdown_content = frontmatter + processed_content
        
        # Save to content directory
        slug = blog_post.get('slug', f"tech-digest-{datetime.now().strftime('%Y-%m-%d')}")
        output_file = os.path.join(self.content_dir, f"{slug}.md")
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(markdown_content)
        
        print(f"âœ… Saved: {output_file}")
        return output_file
    
    def generate_content_from_metadata(self, metadata: Dict, trends_analysis: Dict) -> str:
        """Genera contenido a partir de metadata cuando el content principal falta"""
        today = datetime.now()
        
        content = f"""# Panorama TecnolÃ³gico del {today.strftime('%d de %B, %Y')}

La industria tecnolÃ³gica continÃºa su evoluciÃ³n acelerada con {metadata.get('total_stories', 0)} desarrollos significativos detectados en las Ãºltimas 24 horas.

## ğŸ“Š AnÃ¡lisis del DÃ­a

**Fuentes analizadas:** {', '.join(metadata.get('sources', ['Hacker News', 'TechCrunch', 'Wired']))}

**DistribuciÃ³n por categorÃ­as:**"""

        # Add category breakdown
        categories = metadata.get('categories', {})
        for category, count in categories.items():
            content += f"\n- **{category}:** {count} historias"
        
        content += f"""

## ğŸ” Aspectos Destacados

La jornada de hoy refleja un enfoque particular en {max(categories.items(), key=lambda x: x[1])[0] if categories else 'desarrollo tecnolÃ³gico'}, con mÃºltiples innovaciones que continÃºan moldeando el panorama digital actual.

### Tendencias Emergentes

Los desarrollos observados sugieren una consolidaciÃ³n en las tecnologÃ­as de {', '.join(list(categories.keys())[:3])} que estÃ¡n redefiniendo los estÃ¡ndares de la industria.

## ğŸ’¡ Perspectivas

Estas innovaciones representan oportunidades significativas para profesionales y empresas que buscan mantenerse a la vanguardia tecnolÃ³gica. La velocidad de adopciÃ³n y la diversidad de aplicaciones indican un momento crucial para la toma de decisiones estratÃ©gicas en tecnologÃ­a.

---

*AnÃ¡lisis generado automÃ¡ticamente por **NovaSecOps** - Inteligencia artificial especializada en ciberseguridad y anÃ¡lisis tecnolÃ³gico.*
*Datos recopilados y procesados desde mÃºltiples fuentes tecnolÃ³gicas de primer nivel.*
"""
        
        return content
    
    def format_trends_analysis(self, trends_analysis: Dict) -> str:
        """Formatea el anÃ¡lisis de tendencias en Markdown"""
        if not trends_analysis or trends_analysis.get('fallback'):
            return ""
        
        trends_md = "\n## ğŸ”¥ AnÃ¡lisis de Tendencias\n"
        
        # Main trends
        if 'tendencias_principales' in trends_analysis:
            trends_md += "\n### ğŸ“ˆ Tendencias Principales\n"
            for trend in trends_analysis['tendencias_principales']:
                trends_md += f"- {trend}\n"
        
        # Executive summary
        if 'resumen_ejecutivo' in trends_analysis:
            trends_md += f"\n### ğŸ’¼ Resumen Ejecutivo\n\n{trends_analysis['resumen_ejecutivo']}\n"
        
        # Predictions
        if 'predicciones' in trends_analysis:
            trends_md += "\n### ğŸ”® Predicciones\n"
            if isinstance(trends_analysis['predicciones'], list):
                for prediction in trends_analysis['predicciones']:
                    trends_md += f"- {prediction}\n"
            else:
                trends_md += f"{trends_analysis['predicciones']}\n"
        
        # Business impact
        if 'impacto_empresarial' in trends_analysis:
            trends_md += f"\n### ğŸ¢ Impacto Empresarial\n\n{trends_analysis['impacto_empresarial']}\n"
        
        return trends_md
    
    def update_index_data(self, recent_posts: list):
        """Actualiza datos para la pÃ¡gina principal"""
        index_data = {
            "latest_posts": recent_posts[:5],
            "total_posts": len(recent_posts),
            "last_update": datetime.now().isoformat(),
            "categories": self.extract_categories(recent_posts)
        }
        
        with open(os.path.join(self.public_dir, 'index-data.json'), 'w', encoding='utf-8') as f:
            json.dump(index_data, f, indent=2, ensure_ascii=False)
    
    def extract_categories(self, posts: list) -> Dict:
        """Extrae categorÃ­as de todos los posts"""
        categories = {}
        for post in posts:
            if 'metadata' in post and 'categories' in post['metadata']:
                for category, count in post['metadata']['categories'].items():
                    categories[category] = categories.get(category, 0) + count
        return categories

def main():
    """Ejecutar conversiÃ³n de blog post"""
    print("ğŸ“ Markdown Generator - Blog Vercel")
    print("=" * 50)
    
    # Find latest blog post JSON
    blog_files = [f for f in os.listdir('.') if f.startswith('blog_post_') and f.endswith('.json')]
    if not blog_files:
        print("âŒ No blog post found. Run ai_content_processor.py first.")
        return
    
    # Use latest blog post
    latest_blog = sorted(blog_files)[-1]
    print(f"ğŸ“„ Processing: {latest_blog}")
    
    generator = MarkdownGenerator()
    markdown_file = generator.convert_blog_post_to_markdown(latest_blog)
    
    print(f"\nâœ… Conversion completed!")
    print(f"ğŸ“ Markdown saved to: {markdown_file}")
    print(f"\nğŸš€ Ready for Next.js build!")

if __name__ == "__main__":
    main()